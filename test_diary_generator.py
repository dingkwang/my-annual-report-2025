#!/usr/bin/env python3
"""
Integration test for diary generator
Tests the core functionality without making actual LLM calls
"""

import json
import tempfile
from pathlib import Path
from unittest.mock import Mock, patch

import pytest
import yaml

from diary_generator import DiaryGenerator, DayDiary


@pytest.fixture
def temp_environment():
    """Create temporary test environment"""
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)

        # Create test config
        test_config = {
            'llm': {
                'model': 'grok-test',
                'base_url': 'http://test',
                'api_key': 'test-key',
                'temperature': 0.3,
                'max_tokens': 1000
            },
            'diary_settings': {
                'min_conversation_length': 10,
                'output_format': 'markdown'
            },
            'output': {
                'base_dir': str(temp_path / 'output' / 'diaries'),
                'organize_by': 'year'
            },
            'logging': {
                'level': 'INFO',
                'file': str(temp_path / 'logs' / 'test.log')
            }
        }

        # Write test config
        config_path = temp_path / 'test_config.yaml'
        with open(config_path, 'w') as f:
            yaml.dump(test_config, f)

        yield {
            'temp_path': temp_path,
            'config_path': config_path,
            'test_config': test_config
        }


@pytest.fixture
def test_conversations():
    """Test conversation data"""
    return {
        "2023-01-08": [
            {
                "title": "RLHFä¸‰é˜¶æ®µè§£é‡Š",
                "create_time": 1673150000.0,
                "update_time": 1673151000.0,
                "messages": [
                    {
                        "author": "user",
                        "text": "è¯·è¯¦ç»†è§£é‡ŠRLHFçš„ä¸‰ä¸ªé˜¶æ®µæ˜¯ä»€ä¹ˆï¼Ÿ",
                        "create_time": 1673150000.0
                    },
                    {
                        "author": "assistant",
                        "text": "RLHFï¼ˆReinforcement Learning from Human Feedbackï¼‰åŒ…å«ä¸‰ä¸ªä¸»è¦é˜¶æ®µï¼š1. ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰2. å¥–åŠ±æ¨¡åž‹è®­ç»ƒ 3. å¼ºåŒ–å­¦ä¹ ä¼˜åŒ–",
                        "create_time": 1673150100.0
                    }
                ]
            }
        ],
        "2023-01-09": [
            {
                "title": "Pythonå¼‚æ­¥ç¼–ç¨‹",
                "create_time": 1673236400.0,
                "update_time": 1673237400.0,
                "messages": [
                    {
                        "author": "user",
                        "text": "Pythonä¸­async/awaitæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
                        "create_time": 1673236400.0
                    },
                    {
                        "author": "assistant",
                        "text": "Pythonçš„async/awaitæ˜¯åç¨‹çš„è¯­æ³•ç³–ï¼Œç”¨äºŽç¼–å†™å¼‚æ­¥ä»£ç ã€‚asyncå®šä¹‰åç¨‹å‡½æ•°ï¼Œawaitç”¨äºŽç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆã€‚",
                        "create_time": 1673236500.0
                    }
                ]
            }
        ]
    }


@pytest.fixture
def mock_llm_responses():
    """Mock LLM responses"""
    return [
        DayDiary(
            title="æŽ¢è®¨RLHFæŠ€æœ¯",
            content="ä»Šå¤©ä¸»è¦å’ŒAIåŠ©æ‰‹è®¨è®ºäº†RLHFï¼ˆäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼‰çš„æŠ€æœ¯ç»†èŠ‚ã€‚äº†è§£åˆ°RLHFåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µï¼šç›‘ç£å¾®è°ƒã€å¥–åŠ±æ¨¡åž‹è®­ç»ƒå’Œå¼ºåŒ–å­¦ä¹ ä¼˜åŒ–ã€‚è¿™äº›çŸ¥è¯†å¯¹ç†è§£çŽ°ä»£è¯­è¨€æ¨¡åž‹çš„è®­ç»ƒè¿‡ç¨‹å¾ˆæœ‰å¸®åŠ©ã€‚"
        ),
        DayDiary(
            title="å­¦ä¹ Pythonå¼‚æ­¥ç¼–ç¨‹",
            content="ä»Šå¤©ç»§ç»­å­¦ä¹ ç¼–ç¨‹çŸ¥è¯†ï¼Œé‡ç‚¹äº†è§£äº†Pythonçš„å¼‚æ­¥ç¼–ç¨‹æœºåˆ¶ã€‚æ˜¨å¤©å­¦ä¹ äº†æœºå™¨å­¦ä¹ ç›¸å…³å†…å®¹ï¼Œä»Šå¤©è½¬å‘äº†å®žç”¨çš„ç¼–ç¨‹æŠ€æœ¯ã€‚æŽŒæ¡äº†async/awaitçš„åŸºæœ¬æ¦‚å¿µï¼Œç†è§£äº†åç¨‹åœ¨Pythonä¸­çš„å®žçŽ°æ–¹å¼ã€‚"
        )
    ]


def test_diary_generator_initialization(temp_environment):
    """Test basic initialization"""
    config_path = temp_environment['config_path']

    mock_agent = Mock()
    with patch.object(DiaryGenerator, '_init_agent', return_value=mock_agent):
        generator = DiaryGenerator(str(config_path))
        assert generator.full_context == ""
        assert len(generator.generated_diaries) == 0


def test_conversation_preprocessing(temp_environment, test_conversations):
    """Test conversation preprocessing"""
    config_path = temp_environment['config_path']

    mock_agent = Mock()
    with patch.object(DiaryGenerator, '_init_agent', return_value=mock_agent):
        generator = DiaryGenerator(str(config_path))
        processed = generator._preprocess_conversations(test_conversations["2023-01-08"])

        assert "RLHFä¸‰é˜¶æ®µè§£é‡Š" in processed
        assert "æˆ‘ï¼š" in processed
        assert "AIåŠ©æ‰‹ï¼š" in processed
        assert "è¯·è¯¦ç»†è§£é‡ŠRLHFçš„ä¸‰ä¸ªé˜¶æ®µ" in processed


def test_diary_generation_with_context(temp_environment, test_conversations, mock_llm_responses):
    """Test diary generation with context accumulation"""
    config_path = temp_environment['config_path']
    temp_path = temp_environment['temp_path']

    # Write test data
    test_data_path = temp_path / 'test_conversations.json'
    with open(test_data_path, 'w', encoding='utf-8') as f:
        json.dump(test_conversations, f, ensure_ascii=False)

    # Mock agent
    mock_agent = Mock()
    mock_agent.invoke.side_effect = [
        {"structured_response": resp} for resp in mock_llm_responses
    ]

    with patch.object(DiaryGenerator, '_init_agent', return_value=mock_agent):
        generator = DiaryGenerator(str(config_path))
        generator.generate_all_diaries(str(test_data_path))

    # Verify context accumulation
    assert len(generator.full_context) > 0
    assert "æŽ¢è®¨RLHFæŠ€æœ¯" in generator.full_context
    assert "å­¦ä¹ Pythonå¼‚æ­¥ç¼–ç¨‹" in generator.full_context

    # Verify both diaries were generated
    assert len(generator.generated_diaries) == 2


def test_file_output_structure(temp_environment, test_conversations, mock_llm_responses):
    """Test output file structure"""
    config_path = temp_environment['config_path']
    temp_path = temp_environment['temp_path']
    test_config = temp_environment['test_config']

    # Write test data
    test_data_path = temp_path / 'test_conversations.json'
    with open(test_data_path, 'w', encoding='utf-8') as f:
        json.dump(test_conversations, f, ensure_ascii=False)

    # Mock agent
    mock_agent = Mock()
    mock_agent.invoke.side_effect = [
        {"structured_response": resp} for resp in mock_llm_responses
    ]

    with patch.object(DiaryGenerator, '_init_agent', return_value=mock_agent):
        generator = DiaryGenerator(str(config_path))
        generator.generate_all_diaries(str(test_data_path))

    # Check file structure
    output_dir = Path(test_config['output']['base_dir'])
    assert (output_dir / '2023').exists()

    diary1 = output_dir / '2023' / '2023-01-08.md'
    diary2 = output_dir / '2023' / '2023-01-09.md'
    assert diary1.exists()
    assert diary2.exists()

    # Check content structure
    with open(diary1, 'r', encoding='utf-8') as f:
        content = f.read()
        assert "# æŽ¢è®¨RLHFæŠ€æœ¯" in content
        assert "**æ—¥æœŸ**: 2023-01-08" in content
        assert "RLHF" in content


def test_progress_tracking(temp_environment, test_conversations, mock_llm_responses):
    """Test progress tracking functionality"""
    config_path = temp_environment['config_path']
    temp_path = temp_environment['temp_path']

    # Clean up any existing progress file
    progress_file = Path('progress.json')
    if progress_file.exists():
        progress_file.unlink()

    # Write test data
    test_data_path = temp_path / 'test_conversations.json'
    with open(test_data_path, 'w', encoding='utf-8') as f:
        json.dump(test_conversations, f, ensure_ascii=False)

    # Mock agent
    mock_agent = Mock()
    mock_agent.invoke.side_effect = [
        {"structured_response": resp} for resp in mock_llm_responses
    ]

    with patch.object(DiaryGenerator, '_init_agent', return_value=mock_agent):
        generator = DiaryGenerator(str(config_path))
        generator.generate_all_diaries(str(test_data_path))

    # Check progress file
    assert progress_file.exists()
    with open(progress_file, 'r') as f:
        progress = json.load(f)
        assert '2023-01-08' in progress['processed_dates']
        assert '2023-01-09' in progress['processed_dates']
        assert progress['last_processed'] == '2023-01-09'

    # Clean up
    progress_file.unlink()


def test_context_references_in_second_diary(temp_environment, test_conversations, mock_llm_responses):
    """Test that second diary references context from first"""
    config_path = temp_environment['config_path']
    temp_path = temp_environment['temp_path']

    # Write test data
    test_data_path = temp_path / 'test_conversations.json'
    with open(test_data_path, 'w', encoding='utf-8') as f:
        json.dump(test_conversations, f, ensure_ascii=False)

    # Mock agent
    mock_agent = Mock()
    mock_agent.invoke.side_effect = [
        {"structured_response": resp} for resp in mock_llm_responses
    ]

    with patch.object(DiaryGenerator, '_init_agent', return_value=mock_agent):
        generator = DiaryGenerator(str(config_path))
        generator.generate_all_diaries(str(test_data_path))

    # Check that the second diary mentions previous content
    output_dir = Path(temp_environment['test_config']['output']['base_dir'])
    diary2 = output_dir / '2023' / '2023-01-09.md'

    with open(diary2, 'r', encoding='utf-8') as f:
        content = f.read()
        # The mock response includes a reference to yesterday's learning
        assert "æ˜¨å¤©å­¦ä¹ äº†æœºå™¨å­¦ä¹ " in content


def test_diary_generator_integration():
    """Legacy test function for standalone execution"""
    print("ðŸ§ª Running integration test for DiaryGenerator...")

    # Run all pytest tests programmatically
    pytest.main([__file__, "-v"])

    print("\nðŸŽ‰ All integration tests completed!")
    print("\nKey features tested:")
    print("  âœ“ Configuration loading")
    print("  âœ“ Diary generation with structured output")
    print("  âœ“ Context accumulation (like podcastify)")
    print("  âœ“ File organization by year")
    print("  âœ“ Progress tracking")
    print("  âœ“ Conversation preprocessing")
    print("  âœ“ Context references between diaries")


if __name__ == "__main__":
    test_diary_generator_integration()